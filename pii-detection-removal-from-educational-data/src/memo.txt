v1.2
split input to make the maximum length of input 1024



v1.3
downsample




v2.0
optuna
google colab



v3.0
create a loss function suitable for the objective function f5
b5 threthold 0.9



v4.0
create new dataset to train the model
    https://www.kaggle.com/competitions/pii-detection-removal-from-educational-data/discussion/472221
    https://www.kaggle.com/competitions/pii-detection-removal-from-educational-data/discussion/483058
    https://www.kaggle.com/competitions/pii-detection-removal-from-educational-data/discussion/480747
    https://www.kaggle.com/competitions/pii-detection-removal-from-educational-data/discussion/477989
    https://www.kaggle.com/competitions/pii-detection-removal-from-educational-data/discussion/478911
then, optuna again



v5.0
consider trailing_whitespace
LSTM
/n/n -> to some special token like [KAIGYO]
" " -> to some special token like [SPACE] ?
avarage the result of each fold
weighted avarage the result of each fold
input min, av, max, std to LGBM



v6.0
find the other model to ansamble















MEMO:
batch_size * steps = total number of the data
step size is defined by the batch size automatically
the step count is different between P100 and T4x2 because the batch size is different
how to define the batch size?
if I can define the batch size manually, the step size for the P100 and T4x2 will be the same
P100: 2553 steps, 2553 / 3 = 851 (steps), 6807 / 851 = 8  (batch size)
T4x2: 1278 steps, 1278 / 3 = 426 (steps), 6807 / 426 = 16 (batch size)
epoch = the number of learning using the whole data
T4x2: 1278 / 3 = 426 (steps), 6807 / 426 = 16 (batch size)
input_ids
    X. 260
    .  323
    X, 261  
    ,  366
    X; 346 
    ;  2600

