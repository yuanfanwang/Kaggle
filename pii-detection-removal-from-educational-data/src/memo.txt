# v0.1 TODO:
# (done)        epoch (the size is 3 as default?)
# (done)        batch (fix the size as 8 or 16)

# v0.2:
# (done)        AutoModelForTokenClassification

# v0.3:
# (done)        fold, how to define the fold, cross validation

# v0.4:
# train_by_fold, validate, predict



# v1.0:
# sample submission

# v2.0:
# trailing_whitespace
# parameter tuning (optuna)
# find the best loss func for the evaluation func F5

# v3.0:
# use google colab to train the model using devera-v3-xlarge

# v4.0:
# create new dataset to train the model strongly


# v5.0:
# find the other model to fusion the model





# MEMO:
# batch_size * steps = total number of the data
# step size is defined by the batch size automatically
# the step count is different between P100 and T4x2 because the batch size is different
# how to define the batch size?
# if I can define the batch size manually, the step size for the P100 and T4x2 will be the same
# P100: 2553 steps, 2553 / 3 = 851 (steps), 6807 / 851 = 8  (batch size)
# T4x2: 1278 steps, 1278 / 3 = 426 (steps), 6807 / 426 = 16 (batch size)
# epoch = the number of learning using the whole data

# T4x2: 1278 / 3 = 426 (steps), 6807 / 426 = 16 (batch size)